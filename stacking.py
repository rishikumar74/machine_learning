# -*- coding: utf-8 -*-
"""stacking.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HULIDzel35HNRclbqOTElC3GmoAZwSjQ
"""

from google.colab import drive
import pandas as pd


drive.mount('/content/drive')


df = pd.read_csv('/content/Social_Network_Ads.csv')
df.head()

import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import StackingClassifier
from sklearn.metrics import *
import seaborn as sns
import matplotlib.pyplot as plt

df.isnull().sum()

df.dtypes

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
df

x=df.drop(columns=['User ID','Gender','Purchased'])
y=df['Purchased']

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

sc=StandardScaler()
x_train=sc.fit_transform(x_train)
x_test=sc.transform(x_test)

base_models=[
    ('lr',LogisticRegression()),
    ('dt',DecisionTreeClassifier(max_depth=3)),
    ('knn',KNeighborsClassifier(n_neighbors=5))
]

"""meta model decides how to combine predictions

"""

meta_model=LogisticRegression()

"""building stacking classifier

"""

classifier=StackingClassifier(
  estimators=base_models,
  final_estimator=meta_model,
  cv=5
)
classifier.fit(x_train,y_train)

y_pred=classifier.predict(x_test)
accuracy_score(y_test,y_pred)

print(classification_report(y_test,y_pred))

confusion_matrix(y_test,y_pred)



"""House prediction

"""

import kagglehub
import pandas as pd
import os

# Download dataset
path = kagglehub.dataset_download("harlfoxem/housesalesprediction")

print("Path to dataset files:", path)

# List files in the folder
print("Files:", os.listdir(path))

# Load CSV file (usually this filename)
df = pd.read_csv(os.path.join(path, "kc_house_data.csv"))

# Display first 5 rows
df.head()

df.isnull().sum()

df.dtypes

x=df.drop(columns=['id','date','price'])
y=df['price']



from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor

base_models=[
    ('le',LinearRegression()),
    ('str',DecisionTreeRegressor(max_depth=3)),
    ('rfr',RandomForestRegressor(n_estimators=10,max_depth=3))
]

meta_model=LinearRegression()

from sklearn.ensemble import StackingRegressor
stack_model = StackingRegressor(
    estimators=base_models,
    final_estimator=meta_model,
    cv=5
)

from sklearn.metrics import *
stack_model.fit(x_train, y_train)
y_pred=stack_model.predict(x_test)
mean_squared_error(y_test,y_pred)**0.5

mean_absolute_error(y_test,y_pred)

df.shape

